{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNtAgbQa8bqzEF24m6gqKAU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qksL9EL6ahZ4"},"outputs":[],"source":["import tensorflow as tf### models\n","import numpy as np### math computations\n","import matplotlib.pyplot as plt### plotting bar chart\n","import sklearn### machine learning library\n","import cv2## image processing\n","from sklearn.metrics import confusion_matrix, roc_curve### metrics\n","import seaborn as sns### visualizations\n","import datetime\n","import pathlib\n","import io\n","import os\n","import re\n","import string\n","import time\n","from numpy import random\n","import tensorflow_datasets as tfds\n","import tensorflow_probability as tfp\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,LayerNormalization,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input,MultiHeadAttention,Embedding,TextVectorization)\n","from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n","from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n","from google.colab import drive\n","from google.colab import files\n","from tensorboard.plugins import projector"]},{"cell_type":"markdown","source":["# **Data Preparation**"],"metadata":{"id":"jdWXT0uLbVxV"}},{"cell_type":"markdown","source":["#1- Data Loading"],"metadata":{"id":"9B9tlf17bqqa"}},{"cell_type":"code","source":["!wget https://www.manythings.org/anki/fra-eng.zip"],"metadata":{"id":"6R6V9l_kap9T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip \"/content/fra-eng.zip\" -d \"/content/dataset/\""],"metadata":{"id":"gci_3U_OaqAK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Preprocessing"],"metadata":{"id":"44mqlfkQbwVB"}},{"cell_type":"code","source":["text_dataset=tf.data.TextLineDataset(\"/content/dataset/fra.txt\")"],"metadata":{"id":"ixY4rzT0aqDB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["VOCAB_SIZE=20000\n","ENGLISH_SEQUENCE_LENGTH=32\n","FRENCH_SEQUENCE_LENGTH=32\n","EMBEDDING_DIM=256\n","BATCH_SIZE=128"],"metadata":{"id":"GHkrKl1eaqGB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["english_vectorize_layer=TextVectorization(\n","    standardize='lower_and_strip_punctuation',\n","    max_tokens=VOCAB_SIZE,\n","    output_mode='int',\n","    output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",")"],"metadata":{"id":"d-nOrG4-aqI3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["french_vectorize_layer=TextVectorization(\n","    standardize='lower_and_strip_punctuation',\n","    max_tokens=VOCAB_SIZE,\n","    output_mode='int',\n","    output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",")"],"metadata":{"id":"Nk0WZQL0aqLw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def selector(input_text):\n","  split_text=tf.strings.split(input_text,'\\t')\n","  return {'input_1':split_text[0:1],'input_2':'starttoken '+split_text[1:2]},split_text[1:2]+' endtoken'"],"metadata":{"id":"iQdYgX5xaqOw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["split_dataset=text_dataset.map(selector)"],"metadata":{"id":"WvhOkJwab_xN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def separator(input_text):\n","  split_text=tf.strings.split(input_text,'\\t')\n","  return split_text[0:1],'starttoken '+split_text[1:2]+' endtoken'"],"metadata":{"id":"pNonb_lPb_0D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["init_dataset=text_dataset.map(separator)"],"metadata":{"id":"h5YYJ2A_b_3K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in split_dataset.take(3):\n","  print(i)"],"metadata":{"id":"A8a3bUqYb_6j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["english_training_data=init_dataset.map(lambda x,y:x)### input x,y and output x\n","english_vectorize_layer.adapt(english_training_data)#### adapt the vectorize_layer to the training data"],"metadata":{"id":"KS2mJneDcAEI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["french_training_data=init_dataset.map(lambda x,y:y)### input x,y and output y\n","french_vectorize_layer.adapt(french_training_data)#### adapt the vectorize_layer to the training data"],"metadata":{"id":"ruN11wUKcAVE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vectorizer(inputs,output):\n","  return {'input_1':english_vectorize_layer(inputs['input_1']),\n","          'input_2':french_vectorize_layer(inputs['input_2'])},french_vectorize_layer(output)"],"metadata":{"id":"hwtLMvMnaqRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["split_dataset"],"metadata":{"id":"H5XLoV_jaqVB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset=split_dataset.map(vectorizer)"],"metadata":{"id":"Yu7OwMo-cQhv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in split_dataset.take(3):\n","  print(i)"],"metadata":{"id":"AwyH9_NVcQks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in dataset.take(1):\n","  print(i)"],"metadata":{"id":"fKZIdRnrcQnl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"id":"xArtNBAtcQrB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"],"metadata":{"id":"nsik0WArcZrG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"id":"larSDx10cZuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NUM_BATCHES=int(200000/BATCH_SIZE)"],"metadata":{"id":"QKsPxyXbcZw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n","val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"],"metadata":{"id":"s_C22IhocZz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset"],"metadata":{"id":"GJbp0yrNcZ2x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Model Building**"],"metadata":{"id":"uWfhiIoPck1b"}},{"cell_type":"code","source":["# Embedding"],"metadata":{"id":"4vnfdj9vcZ5q","executionInfo":{"status":"ok","timestamp":1703432098596,"user_tz":-180,"elapsed":5505,"user":{"displayName":"Kempsly Silencieux","userId":"03106040422226631399"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def positional_encoding(model_size,   SEQUENCE_LENGTH):\n","  output=[]\n","  for pos in range(SEQUENCE_LENGTH):\n","    PE=np.zeros((model_size))\n","    for i in range(model_size):\n","      if i%2==0:\n","        PE[i]=np.sin(pos/(10000**(i/model_size)))\n","      else:\n","        PE[i]=np.cos(pos/(10000**((i-1)/model_size)))\n","    output.append(tf.expand_dims(PE,axis=0))\n","  out=tf.concat(output, axis=0)\n","  out=tf.expand_dims(out,axis=0)\n","  return tf.cast(out, dtype=tf.float32)"],"metadata":{"id":"bTNYarx9cZ8j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(positional_encoding(256,64).shape)"],"metadata":{"id":"MSHObqCZdyH1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Embeddings(Layer):\n","  def __init__(self, sequence_length, vocab_size, embed_dim, ):\n","    super(Embeddings, self).__init__()\n","    self.token_embeddings=Embedding(input_dim=vocab_size, output_dim=embed_dim)\n","    self.sequence_length=sequence_length\n","    self.vocab_size=vocab_size\n","    self.embed_dim=embed_dim\n","\n","  def call(self, inputs):\n","    embedded_tokens = self.token_embeddings(inputs)\n","    embedded_positions=positional_encoding(self.embed_dim, self.sequence_length)\n","\n","    return embedded_tokens + embedded_positions\n","\n","  def compute_mask(self, inputs, mask=None):\n","    return tf.math.not_equal(inputs, 0)"],"metadata":{"id":"1CnIjIWRdyKz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_input=tf.constant([[2,4,7,21,3,5,0,0]])\n","emb=Embeddings(8,20000,512)\n","emb_out=emb(test_input)\n","print(emb_out.shape)"],"metadata":{"id":"hX8Oy7qIdyN0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mask = emb.compute_mask(test_input)\n","print(mask)\n","\n","padding_mask = tf.cast(tf.repeat(mask, repeats=tf.shape(mask)[1], axis=0),\n","                       dtype=tf.int32)\n","print(padding_mask)"],"metadata":{"id":"dqdbpUZEdyQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tf.linalg.band_part(\n","        tf.ones([1,8, 8],dtype=tf.int32),-1,0))"],"metadata":{"id":"Hg3AC24qdyTl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Custom MultiHeadAttention"],"metadata":{"id":"oBfXfwhjhIm6"}},{"cell_type":"code","source":["class CustomSelfAttention(Layer):\n","  def __init__(self, model_size):\n","    super(CustomSelfAttention, self).__init__()\n","    self.model_size=model_size\n","\n","  def call(self, query, key, value, masking):\n","    score=tf.malmul(query, key, transpose_b=True)\n","    score/=tf=tf.math.sqrt(tf.cast(self.model_size, tf.float32))\n","    masking=tf.cast(masking, dtype=tf.float32)\n","    score+=(1.-masking)*-1e10\n","    attention=tf.nn.softmax(score, axis=-1)*masking\n","    head=tf.matmul(attention, value)\n","\n","    return head"],"metadata":{"id":"matiEU_EdyWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attention=CustomSelfAttention(256)\n","attention(tf.ones([1,8,256]),tf.ones([1,8,256]),tf.ones([1,8,256]),padding_mask)"],"metadata":{"id":"7_tvd3LodyZh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomMultiHeadAttention(Layer):\n","  def __init__(self, num_heads, key_dim):\n","    super(CustomMultiHeadAttention, self).__init__()\n","\n","    self.num_heads=num_heads\n","    self.dense_q=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n","    self.dense_k=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n","    self.dense_v=[Dense(key_dim//num_heads) for _ in range(num_heads)]\n","    self.dense_o=Dense(key_dim)\n","    self.self_attention=CustomMultiHeadAttention(key_dim)\n","\n","  def call(self, query, key, value, attention_mask):\n","    heads=[]\n","\n","    for i in range(self.num_heads):\n","      print(\"hello\", self.dense_q[i](query), self.dense_k[i](key), self.dense_v[i](value), attention_mask)\n","      heads.append(head)\n","\n","    heads=tf.concat(heads, axis=2)\n","    heads=self.dense_o(heads)\n","    return heads\n","\n"],"metadata":{"id":"xyQee45odycf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Encoder"],"metadata":{"id":"ejREE4ORksZF"}},{"cell_type":"code","source":["class TransformerEncoder(Layer):\n","  def __init__(self, embed_dim, dense_dim, num_heads, ):\n","    super(TransformerEncoder, self).__init__()\n","    self.embed_dim = embed_dim\n","    self.dense_dim = dense_dim\n","    self.num_heads = num_heads\n","    self.attention = CustomMultiHeadAttention(num_heads=num_heads, key_dim=embed_dim,)\n","    self.dense_proj=tf.keras.Sequential([\n","        Dense(dense_dim, activation=\"relu\"),\n","        Dense(embed_dim),\n","    ])\n","    self.layernorm_1 = LayerNormalization()\n","    self.layernorm_2 = LayerNormalization()\n","    self.supports_masking =True\n","\n","  def call(self, inputs, mask=None):\n","\n","    if mask is not None:\n","      mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n","      T = tf.shape(mask)[2]\n","      padding_mask = tf.repeat(mask, T, axis=1)\n","      attention_output = self.attention(query=inputs, key=inputs, value=inputs, attention_mask=padding_mask)\n","\n","      proj_input = self.layernorm_1(inputs + attention_output)\n","      proj_output = self.dense_proj(proj_intput)\n","\n","      return self.layernorm_2(proj_input + proj_output)\n","\n"],"metadata":{"id":"1ZKG5x4odyfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_outputs = TransformerEncoder(512,2048,8)(emb_out)\n","print(encoder_outputs.shape)\n"],"metadata":{"id":"NwghP2o7dyin"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#DEcoder"],"metadata":{"id":"s4UACPW4nI4h"}},{"cell_type":"code","source":["print(tf.linalg.band_part(\n","        tf.ones([1,8, 8],dtype=tf.int32),-1,0))"],"metadata":{"id":"S3xdB8TvdymM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TransformerDecoder(Layer):\n","  def __init__(self, embed_dim, latent_dim, num_heads,):\n","    super(TransformerDecoder, self).__init__()\n","    self.embed_dim = embed_dim\n","    self.latent_dim = latent_dim\n","    self.num_heads = num_heads\n","    self.attention_1=MultiHeadAttention(\n","        num_heads=num_heads, key_dim=embed_dim\n","    )\n","    self.attention_2=MultiHeadAttention(\n","        num_heads=num_heads, key_dim=embed_dim\n","    )\n","    self.dense_proj = tf.keras.Sequential(\n","        [Dense(latent_dim, activation=\"relu\"),Dense(embed_dim),]\n","    )\n","    self.layernorm_1=LayerNormalization()\n","    self.layernorm_2=LayerNormalization()\n","    self.layernorm_3=LayerNormalization()\n","    self.supports_masking = True\n","\n","\n","  def call(self, inputs, encoder_outputs, enc_mask, mask=None):\n","\n","\n","    if mask is not None:\n","      causal_mask=tf.linalg.band_part(\n","        tf.ones([tf.shape(inputs)[0],\n","                 tf.shape(inputs)[1],\n","                 tf.shape(inputs)[1]],dtype=tf.int32),-1,0)\n","      mask = tf.cast(\n","          mask[:,tf.newaxis, :], dtype=\"int32\")\n","      enc_mask = tf.cast(\n","          enc_mask[:,tf.newaxis, :], dtype=\"int32\")\n","\n","      T = tf.shape(mask)[2]\n","      padding_mask = tf.repeat(mask,T,axis=1)\n","      cross_attn_mask = tf.repeat(enc_mask,T,axis=1)\n","      combined_mask=tf.minimum(padding_mask,causal_mask)\n","\n","    attention_output_1 = self.attention_1(\n","        query=inputs,key=inputs,value=inputs,\n","        attention_mask=combined_mask,\n","\n","    )\n","\n","    out_1 = self.layernorm_1(inputs + attention_output_1)\n","\n","    attention_output_2= self.attention_2(\n","        query=out_1,key=encoder_outputs,value=encoder_outputs,\n","        attention_mask=cross_attn_mask,\n","\n","    )\n","    out_2 = self.layernorm_2(out_1 + attention_output_2)\n","\n","    proj_output = self.dense_proj(out_2)\n","    return self.layernorm_3(out_2 + proj_output)"],"metadata":{"id":"vntr7EnunLaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["enc_mask=mask\n","decoder_outputs = TransformerDecoder(256,2048,4)(emb_out,encoder_outputs,enc_mask)\n","print(decoder_outputs.shape)"],"metadata":{"id":"qgPN05AYnLdT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Transformer Model"],"metadata":{"id":"F9Yg02p5pnqY"}},{"cell_type":"code","source":["EMBEDDING_DIM=512\n","D_FF=2048\n","NUM_HEADS=8\n","NUM_LAYERS=1\n","NUM_EPOCHS=10"],"metadata":{"id":"b5VMVn16nLgX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_1\")\n","emb = Embeddings(ENGLISH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)\n","x = emb(encoder_inputs)\n","enc_mask = emb.compute_mask(encoder_inputs)\n","\n","for _ in range(NUM_LAYERS):\n","  x=TransformerEncoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x)\n","encoder_outputs=x\n","\n","decoder_inputs=Input(shape=(None,), dtype=\"int64\", name=\"input_2\")\n","\n","x = Embeddings(FRENCH_SEQUENCE_LENGTH,VOCAB_SIZE,EMBEDDING_DIM)(decoder_inputs)\n","for i in range(NUM_LAYERS):\n","  x=TransformerDecoder(EMBEDDING_DIM,D_FF,NUM_HEADS)(x, encoder_outputs,enc_mask)\n","x=tf.keras.layers.Dropout(0.5)(x)\n","decoder_outputs=Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n","\n","transformer = tf.keras.Model(\n","    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",")\n","transformer.summary()"],"metadata":{"id":"dK3s2Y3ynLj3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#TRain the model"],"metadata":{"id":"O8GXQxLbswYP"}},{"cell_type":"code","source":["class BLEU(tf.keras.metrics.Metric):\n","    def __init__(self,name='bleu_score'):\n","        super(BLEU,self).__init__()\n","        self.bleu_score=0\n","\n","    def update_state(self,y_true,y_pred,sample_weight=None):\n","      y_pred=tf.argmax(y_pred,-1)\n","      self.bleu_score=0\n","      for i,j in zip(y_pred,y_true):\n","        tf.autograph.experimental.set_loop_options()\n","\n","        total_words=tf.math.count_nonzero(i)\n","        total_matches=0\n","        for word in i:\n","          if word==0:\n","            break\n","          for q in range(len(j)):\n","            if j[q]==0:\n","              break\n","            if word==j[q]:\n","              total_matches+=1\n","              j=tf.boolean_mask(j,[False if y==q else True for y in range(len(j))])\n","              break\n","\n","        self.bleu_score+=total_matches/total_words\n","\n","    def result(self):\n","        return self.bleu_score/BATCH_SIZE"],"metadata":{"id":"2YH5NPj0caDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Scheduler(LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps):\n","    super(Scheduler, self).__init__()\n","    self.d_model = tf.cast(d_model, tf.float64)\n","    self.warmup_steps = tf.cast(warmup_steps, dtype=tf.float64)\n","\n","  def __call__(self, step):\n","    step = tf.cast(step, dtype=tf.float64)\n","    return (self.d_model**(-0.5))*tf.math.minimum(step**(-0.5), step * (self.warmup_steps ** -1.5))"],"metadata":{"id":"jKVk_8Pks2Xu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["WARM_UP_STEPS = 4000\n","lr_scheduled = Scheduler(EMBEDDING_DIM, WARM_UP_STEPS)"],"metadata":{"id":"XWUYx8wXs2an"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer.compile(\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","    optimizer = Adam(lr_scheduled, beta_1=0.9, beta_2=0.98, epsilon=1e-9),)\n","    #metrics=[BLEU()],\n","    #run_eagerly=True)"],"metadata":{"id":"8NdpN-l2s2dh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history=transformer.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=10)"],"metadata":{"id":"mfte_2vus2gh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer.save_weights('/content/drive/MyDrive/transformers.h5')"],"metadata":{"id":"L8wGXUsYs2je"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model_loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"metadata":{"id":"JYwC9am_tdDB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformer.evaluate(val_dataset)"],"metadata":{"id":"JvFXBpiMtdGF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Testing"],"metadata":{"id":"K_ZWYsyctiQ5"}},{"cell_type":"code","source":["index_to_word={x:y for x, y in zip(range(len(french_vectorize_layer.get_vocabulary())),\n","                                   french_vectorize_layer.get_vocabulary())}"],"metadata":{"id":"eqP-3EuutdJU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def translator(english_sentence):\n","  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n","  shifted_target='starttoken'\n","\n","  for i in range(FRENCH_SEQUENCE_LENGTH):\n","    tokenized_shifted_target=french_vectorize_layer([shifted_target])\n","    output=transformer.predict([tokenized_english_sentence,tokenized_shifted_target])\n","    french_word_index=tf.argmax(output,axis=-1)[0][i].numpy()\n","    current_word=index_to_word[french_word_index]\n","    if current_word=='endtoken':\n","      break\n","    shifted_target+=' '+current_word\n","  return shifted_target[11:]"],"metadata":{"id":"CZ5-RdrHtdMW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator('What makes you think that it is not true?')"],"metadata":{"id":"0zXtkfCstqIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator('Have you ever watched soccer under the rain?')"],"metadata":{"id":"6iJKJ-ODtqLl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator(\"what is your name?\")"],"metadata":{"id":"00R79s9ctqPE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator('Great trees do not grow with ease, the stronger the winds, the stronger the trees')"],"metadata":{"id":"XAMpBDYUtqSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator('My hotel told me to call you. ')"],"metadata":{"id":"Nzmjixp3tdP4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator('His French is improving little by little')"],"metadata":{"id":"m1eW_H_Qt42w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator('I love to write')"],"metadata":{"id":"QMb0rObot46D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator('Perhaps she will come tomorrow')"],"metadata":{"id":"Ae0Wee9Nt49r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator('Tom has never heard Mary sing.')"],"metadata":{"id":"tnLB2bPbs2m8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["translator('She handed him the money')"],"metadata":{"id":"4QEhmk6uuC_r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Visualization Part"],"metadata":{"id":"urS1pk27uGQs"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692791800705,"user_tz":-60,"elapsed":615917,"user":{"displayName":"Neuralearn","userId":"14742080128936981241"}},"outputId":"25f9f4f6-28f2-4bf8-b45c-da91e30386c6","id":"DbUDaxSPuSIk"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["def visualize(english_sentence):\n","  tokenized_english_sentence=english_vectorize_layer([english_sentence])\n","  shifted_target='starttoken je lai fait trÃ¨s bien'\n","\n","  tokenized_shifted_target=french_vectorize_layer([shifted_target])\n","  attention_weights=attention_score_model.predict([tokenized_english_sentence,\n","                                                   tokenized_shifted_target])\n","\n","  return attention_weights\n","\n","out=visualize('I did it very well')\n"],"metadata":{"id":"hAseWKh2uDF5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(out['decoder_layer1_block2'][0].shape)"],"metadata":{"id":"aStoewrruXRJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize = (12,12))\n","\n","for i in range(NUM_HEADS):\n","  ax = plt.subplot(2,4, i+1)\n","\n","  plt.imshow(out['decoder_layer1_block2'][0][i][0:10,0:10])\n","  plt.title(\"Attention Scores for head:->\"+str(i+1))"],"metadata":{"id":"gtFhlrhnuXUO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k9voX9xTuXXk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AS4NiCIwuXas"},"execution_count":null,"outputs":[]}]}