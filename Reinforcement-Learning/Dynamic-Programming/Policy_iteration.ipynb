{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPp0/gdI6NxwgdgsusGIH1Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"M6pLT5Ez5eOd","executionInfo":{"status":"ok","timestamp":1732364507688,"user_tz":-180,"elapsed":249,"user":{"displayName":"Kempsly Silencieux","userId":"03106040422226631399"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","source":["import numpy as np\n","\n","class GridworldMDP:\n","    def __init__(self, grid_size=4, gamma=0.9):\n","        self.grid_size = grid_size\n","        self.states = [(i, j) for i in range(grid_size) for j in range(grid_size)]\n","        self.actions = ['up', 'down', 'left', 'right']\n","        self.gamma = gamma\n","        self.rewards = self.create_rewards()\n","        self.transition_probs = self.create_transition_probs()\n","\n","    def create_rewards(self):\n","        rewards = {}\n","        for state in self.states:\n","            rewards[state] = -1\n","        rewards[(0, self.grid_size - 1)] = 10  # Goal state\n","        rewards[(2, 2)] = -10  # Trap state\n","        return rewards\n","\n","    def create_transition_probs(self):\n","        transition_probs = {}\n","        for state in self.states:\n","            transition_probs[state] = {}\n","            for action in self.actions:\n","                transition_probs[state][action] = self.get_next_state_probs(state, action)\n","        return transition_probs\n","\n","    def get_next_state_probs(self, state, action):\n","        i, j = state\n","        if state == (0, self.grid_size - 1):  # Goal state\n","            return {(0, self.grid_size - 1): 1.0}\n","\n","        if action == 'up':\n","            next_state = (max(i - 1, 0), j)\n","        elif action == 'down':\n","            next_state = (min(i + 1, self.grid_size - 1), j)\n","        elif action == 'left':\n","            next_state = (i, max(j - 1, 0))\n","        elif action == 'right':\n","            next_state = (i, min(j + 1, self.grid_size - 1))\n","\n","        return {next_state: 1.0}\n","\n","    def policy_iteration(self):\n","        # Step 1: Initialize random policy\n","        policy = {state: np.random.choice(self.actions) for state in self.states}\n","        V = {state: 0 for state in self.states}\n","\n","        while True:\n","            # Step 2: Policy Evaluation\n","            while True:\n","                delta = 0\n","                for state in self.states:\n","                    old_value = V[state]\n","                    action = policy[state]\n","                    new_value = 0\n","                    for next_state, prob in self.transition_probs[state][action].items():\n","                        new_value += prob * (self.rewards[next_state] + self.gamma * V[next_state])\n","                    V[state] = new_value\n","                    delta = max(delta, abs(old_value - new_value))\n","                if delta < 1e-3:\n","                    break\n","\n","            # Step 3: Policy Improvement\n","            policy_stable = True\n","            for state in self.states:\n","                old_action = policy[state]\n","                action_values = {}\n","                for action in self.actions:\n","                    action_value = 0\n","                    for next_state, prob in self.transition_probs[state][action].items():\n","                        action_value += prob * (self.rewards[next_state] + self.gamma * V[next_state])\n","                    action_values[action] = action_value\n","                best_action = max(action_values, key=action_values.get)\n","                policy[state] = best_action\n","                if old_action != best_action:\n","                    policy_stable = False\n","\n","            if policy_stable:\n","                break\n","\n","        return V, policy\n","\n","    def print_policy(self, policy):\n","        grid_policy = np.zeros((self.grid_size, self.grid_size), dtype=str)\n","        for state, action in policy.items():\n","            i, j = state\n","            grid_policy[i, j] = action[0]  # First letter of the action\n","        print(\"Optimal Policy:\")\n","        for row in grid_policy:\n","            print(' '.join(row))\n","\n","\n","# Create Gridworld MDP\n","gridworld = GridworldMDP(grid_size=4, gamma=0.9)\n","\n","# Solve MDP using Policy Iteration\n","optimal_values, optimal_policy = gridworld.policy_iteration()\n","\n","# Print the results\n","print(\"Optimal Value Function:\")\n","for state, value in sorted(optimal_values.items()):\n","    print(f\"State {state}: {value:.2f}\")\n","\n","print(\"\\nOptimal Policy:\")\n","gridworld.print_policy(optimal_policy)\n"],"metadata":{"id":"y1hl-FHu_7kM","executionInfo":{"status":"ok","timestamp":1732364978935,"user_tz":-180,"elapsed":293,"user":{"displayName":"Kempsly Silencieux","userId":"03106040422226631399"}},"outputId":"4dc8ddf5-74ab-4976-f597-f7d4c2fe0cee","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimal Value Function:\n","State (0, 0): 79.10\n","State (0, 1): 89.00\n","State (0, 2): 100.00\n","State (0, 3): 100.00\n","State (1, 0): 70.19\n","State (1, 1): 79.10\n","State (1, 2): 89.00\n","State (1, 3): 100.00\n","State (2, 0): 62.17\n","State (2, 1): 70.19\n","State (2, 2): 79.10\n","State (2, 3): 89.00\n","State (3, 0): 54.95\n","State (3, 1): 62.17\n","State (3, 2): 70.19\n","State (3, 3): 79.10\n","\n","Optimal Policy:\n","Optimal Policy:\n","r r r u\n","r r r u\n","r u r u\n","r r r u\n"]}]},{"cell_type":"code","source":["def policy_iteration(env, eps=0.1, gamma=1):\n","  #Initialization\n","  np.random.seed(1)\n","  states = env.state_space\n","  actions = env.action_space\n","  policy = {s: {np.random.choice(actions):1} for s in states}\n","  v = {s: 0 for s in states}\n","\n","\n","  while True:\n","    #Policy Evaluation\n","    v = policy_evaluation(env, policy, v=v, eps=eps, gamma=gamma)\n","\n","    old_policy = policy\n","    policy = {}\n","\n","    # Policy Improvement\n","    for s in states:\n","      policy[s], _ = policy_improvement(env, v, s, actions, gamma)\n","\n","    if old_policy == policy:\n","      break\n","  print(\"Optimal policy found!\")\n","  return policy, v"],"metadata":{"id":"Joh4kwY-5hF4","executionInfo":{"status":"ok","timestamp":1732364731093,"user_tz":-180,"elapsed":325,"user":{"displayName":"Kempsly Silencieux","userId":"03106040422226631399"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lCHCLdzk5hJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2nHlGRa75hUr"},"execution_count":null,"outputs":[]}]}