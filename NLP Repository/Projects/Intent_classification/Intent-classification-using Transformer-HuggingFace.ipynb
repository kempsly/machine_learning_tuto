{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNUkK+34W8QTixsPduW2+/i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Installation"],"metadata":{"id":"mVdPs2MFZnmX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzWUifo3Y607"},"outputs":[],"source":["!pip install transformers datasets"]},{"cell_type":"markdown","source":["#Import Statements"],"metadata":{"id":"QrFCYzFQZwQI"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn\n","from sklearn.metrics import confusion_matrix, roc_curve\n","import seaborn as sns\n","import datetime\n","import pathlib\n","import io\n","import os\n","import re\n","import string\n","import time\n","from numpy import random\n","import gensim.downloader as api\n","from PIL import Image\n","import tensorflow_datasets as tfds\n","import tensorflow_probability as tfp\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras.layers import Dense,Flatten,InputLayer,BatchNormalization,Dropout,Input,LayerNormalization\n","from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n","from tensorflow.keras.metrics import (BinaryAccuracy, FalsePositives, FalseNegatives, TruePositives,\n","                                       TrueNegatives, Precision, Recall, AUC, binary_accuracy,Accuracy,\n","                                       TopKCategoricalAccuracy, CategoricalAccuracy,SparseCategoricalAccuracy)\n","from tensorflow.keras.optimizers import Adam\n","from google.colab import drive\n","from google.colab import files\n","from datasets import load_dataset\n","from transformers import (BertTokenizerFast,TFBertTokenizer,BertTokenizer,RobertaTokenizerFast,\n","                          DataCollatorWithPadding,TFRobertaForSequenceClassification,TFBertForSequenceClassification,\n","                          TFBertModel,create_optimizer,TFDebertaForSequenceClassification,DebertaTokenizerFast)"],"metadata":{"id":"OZ6C7uITZkya"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE=16"],"metadata":{"id":"sqJgbQdwZk1Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Preparation"],"metadata":{"id":"9bXTrKflZ9dr"}},{"cell_type":"code","source":["!pip install -q kaggle\n","! mkdir ~/.kaggle\n","! cp kaggle.json ~/.kaggle/\n","!chmod 600 /root/.kaggle/kaggle.json\n","!kaggle datasets download -d bitext/training-dataset-for-chatbotsvirtual-assistants\n","!unzip \"/content/training-dataset-for-chatbotsvirtual-assistants.zip\" -d \"/content/dataset/\""],"metadata":{"id":"vG_Ndj9tZk4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset=load_dataset(\"csv\",\n","                       data_files=\"/content/dataset/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample.csv\")"],"metadata":{"id":"6GN_WICQZk7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"id":"B_12mT_ZZk-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset['train'][0]"],"metadata":{"id":"mBYC_5e6ZlBg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["intents=list(set(dataset['train']['intent']))\n","dict_intents={intents[i]: i for i in range(len(intents))}\n","print(dict_intents)\n","print(len(intents))"],"metadata":{"id":"m9XQv33tZlEu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocess(dataset):\n","  return {'utterance':dataset['utterance'],\n","          'intent':dict_intents[dataset['intent']]}"],"metadata":{"id":"5xleTWzXZlHq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prep_dataset=dataset.map(preprocess)"],"metadata":{"id":"bfvSy_FtZlKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prep_dataset['train'][0]"],"metadata":{"id":"6k9D7RZ3ZlNt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_id=\"microsoft/deberta-base\"\n","tokenizer = DebertaTokenizerFast.from_pretrained(model_id)"],"metadata":{"id":"u05z9Iz9ZlQz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenizer_function(dataset):\n","  return tokenizer(dataset[\"utterance\"],)"],"metadata":{"id":"RIUtf5-tZlTy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset=prep_dataset.map(tokenizer_function)"],"metadata":{"id":"rieR-16AZlXA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset"],"metadata":{"id":"lr2RfG_pZlaA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset['train'][0]"],"metadata":{"id":"fpzYdGauZldI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"],"metadata":{"id":"EVYgdidcZlgq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `DataCollatorWithPadding` class from the Hugging Face `transformers` library is designed to facilitate batch creation and padding for tokenized datasets. This class is particularly useful for preparing batches of tokenized inputs suitable for model training. Let's break down the provided usage of `DataCollatorWithPadding`:\n","\n","### Code Explanation:\n","\n","```python\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n","```\n","\n","- **Initialization**:\n","  - `DataCollatorWithPadding` is initialized with the following parameters:\n","    - `tokenizer`: This parameter is a tokenizer object from Hugging Face Transformers (`tokenizer=tokenizer`).\n","      - The tokenizer is used to handle tokenization and padding of input sequences.\n","    - `return_tensors=\"tf\"`: Specifies the format of the returned tensors.\n","      - `return_tensors=\"tf\"` indicates that the returned batch should be in TensorFlow `tf.Tensor` format.\n"],"metadata":{"id":"Fvb38wQ3f4Ip"}},{"cell_type":"code","source":["tf_dataset = tokenized_dataset[\"train\"].to_tf_dataset(\n","    columns=['input_ids','attention_mask', 'intent'],\n","    shuffle=True,\n","    batch_size=BATCH_SIZE,\n","    collate_fn=data_collator\n",")"],"metadata":{"id":"5OLcmAT-Zlj4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def swap_positions(dataset):\n","  return {'input_ids':dataset['input_ids'],\n","          'attention_mask':dataset['attention_mask'],},dataset['intent']"],"metadata":{"id":"j9-nJEHlZlm8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf_dataset=tf_dataset.map(swap_positions)"],"metadata":{"id":"fe45vlXUZlqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset=tf_dataset.take(int(0.9*len(tf_dataset)))\n","val_dataset=tf_dataset.skip(int(0.9*len(tf_dataset)))"],"metadata":{"id":"_O06xsuZZlta"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in val_dataset.take(1):\n","  print(i)"],"metadata":{"id":"v7BjPkDQZlwy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Modeling"],"metadata":{"id":"g0uWL-0Kg5Nc"}},{"cell_type":"markdown","source":["##With TFDebertaForSequenceClassification"],"metadata":{"id":"wkTZJBxehAq_"}},{"cell_type":"code","source":["model=TFDebertaForSequenceClassification.from_pretrained(model_id,num_labels=len(intents))\n","model.summary()"],"metadata":{"id":"mAPpP0bkZl0P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Training"],"metadata":{"id":"XV2UcMnShtIC"}},{"cell_type":"code","source":["num_epochs = 2\n","batches_per_epoch = len(tokenized_dataset[\"train\"]) // BATCH_SIZE\n","total_train_steps = int(batches_per_epoch * num_epochs)"],"metadata":{"id":"TNwXmxz5Zl3l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer, schedule = create_optimizer(init_lr=2e-5,num_warmup_steps=0, num_train_steps=total_train_steps)"],"metadata":{"id":"bxLnweIGZl6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=optimizer,\n","    metrics=[\"accuracy\"])"],"metadata":{"id":"a4JLf7EbZl96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history=model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=2,)"],"metadata":{"id":"tTL4--aTZmBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model_loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"metadata":{"id":"fTZuifpeZmEa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","\n","plt.title('model_accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"metadata":{"id":"F4VAtI9hZmH2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Evaluation"],"metadata":{"id":"ksO8BGfZh9uB"}},{"cell_type":"code","source":["predicted = []\n","labels = []\n","\n","for input, label in val_dataset:\n","  predicted.append(model(**input).logits)\n","  labels.append(label.numpy())"],"metadata":{"id":"WCndba3wZmLM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Performing inference using a trained model (`model`) on a validation dataset (`val_dataset`) to obtain predictions and compare them with the ground truth labels.\n","\n","### Code Explanation:\n","\n","1. **Iteration over Validation Dataset**:\n","   - Iterate over the validation dataset (`val_dataset`) to obtain batches of inputs (`input`) and corresponding labels (`label`).\n","\n","```python\n","predicted = []\n","labels = []\n","\n","for inputs, labels_batch in val_dataset:\n","    # Process each batch of inputs and labels\n","    logits = model(inputs)  # Assuming model directly outputs logits\n","    predicted.append(logits)\n","    labels.append(labels_batch.numpy())  # Convert labels to numpy array for easier handling\n","```\n","\n","2. **Model Prediction**:\n","   - Use the trained model (`model`) to obtain predictions (`logits`) for each batch of inputs (`inputs`).\n","   - Append the predictions (`logits`) to the `predicted` list.\n","   - Extract the labels (`labels_batch`) from the dataset batch and convert them to a numpy array using `.numpy()` for comparison.\n","\n","3. **Data Handling**:\n","   - Store the model predictions (`predicted`) and ground truth labels (`labels`) for further evaluation.\n","\n"],"metadata":{"id":"rQyAyPH_i_vZ"}},{"cell_type":"code","source":["print(predicted)\n","print(labels)"],"metadata":{"id":"Dk9kOZibZmOj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tf.argmax(predicted[:-1],axis=-1).numpy())\n","print(labels[:-1])"],"metadata":{"id":"55WvkoGgZmRx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(np.concatenate([np.array(labels[:-1]).flatten(),np.array(labels[-1]).flatten()]))\n","print(np.concatenate([np.argmax(predicted[:-1], axis = -1).flatten(), np.argmax(predicted[-1], axis = -1).flatten()]))"],"metadata":{"id":"B3P8IA_bZmVH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","### Code Explanation:\n","\n","1. **Concatenation and Flattening**:\n","   - Use `np.concatenate` to combine the lists of arrays (`labels[:-1]`) and the last array (`labels[-1]`) into a single numpy array.\n","   - Similarly, concatenate the lists of arrays of predicted labels (`predicted[:-1]`) and the last array of predicted labels (`predicted[-1]`).\n","   - Flatten the resulting concatenated arrays to obtain a 1D array of labels and predicted labels.\n","\n","### Revised Code:\n","\n","```python\n","import numpy as np\n","\n","# Concatenate and flatten the ground truth labels (labels) for the entire validation dataset\n","true_labels_concatenated = np.concatenate([np.array(labels[:-1]).flatten(), np.array(labels[-1]).flatten()])\n","\n","# Concatenate and flatten the predicted labels (predicted) for the entire validation dataset\n","predicted_labels_concatenated = np.concatenate([np.argmax(predicted[:-1], axis=-1).flatten(), np.argmax(predicted[-1], axis=-1).flatten()])\n","\n","# Print the concatenated and flattened arrays for comparison\n","print(\"True Labels:\")\n","print(true_labels_concatenated)\n","\n","print(\"Predicted Labels:\")\n","print(predicted_labels_concatenated)\n","```\n","\n","### Notes:\n","\n","- **Concatenation**:\n","  - Use `np.concatenate` to combine the lists of arrays (`labels[:-1]`) and the last array (`labels[-1]`) into a single contiguous array (`true_labels_concatenated`).\n","  - Similarly, concatenate the lists of arrays of predicted labels (`predicted[:-1]`) and the last array of predicted labels (`predicted[-1]`) into `predicted_labels_concatenated`.\n","\n","- **Flattening**:\n","  - Ensure that each array within `labels` and `predicted` is flattened using `.flatten()` before concatenating to obtain a 1D array.\n","\n","- **Comparison**:\n","  - Print the concatenated and flattened arrays (`true_labels_concatenated` and `predicted_labels_concatenated`) to compare the ground truth labels with the predicted labels for the entire validation dataset.\n"],"metadata":{"id":"IB8QMPXxmSng"}},{"cell_type":"code","source":["pred=np.concatenate([np.array(labels[:-1]).flatten(),np.array(labels[-1]).flatten()])\n","lab=np.concatenate([np.argmax(predicted[:-1], axis = -1).flatten(), np.argmax(predicted[-1], axis = -1).flatten()])"],"metadata":{"id":"o90qKMyyZmYQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","Here's a breakdown of what `labels[:-1]` and `labels[-1]` represent:\n","\n","- `labels[:-1]`: This syntax retrieves all elements in the `labels` list except for the last element. It effectively slices the list from the beginning up to (but not including) the last element.\n","  \n","- `labels[-1]`: This syntax retrieves the last element in the `labels` list.\n","\n","### Usage Example:\n","\n","Let's assume `labels` is a list containing arrays of labels (e.g., numpy arrays of ground truth labels) corresponding to batches of data. We can demonstrate the usage of `labels[:-1]` and `labels[-1]` with a simple example:\n","\n","```python\n","import numpy as np\n","\n","# Example list of numpy arrays (simulating ground truth labels for batches)\n","labels = [np.array([1, 2, 3]), np.array([4, 5]), np.array([6, 7, 8, 9])]\n","\n","# Access all elements except the last one (slice from beginning to last element - 1)\n","all_but_last = labels[:-1]\n","print(\"All but last element:\", all_but_last)\n","\n","# Access the last element in the list\n","last_element = labels[-1]\n","print(\"Last element:\", last_element)\n","```\n","\n","In this example:\n","\n","- `all_but_last` contains all elements of `labels` except for the last one. It would be equivalent to `[np.array([1, 2, 3]), np.array([4, 5])]`.\n","  \n","- `last_element` contains the last element of `labels`, which is `np.array([6, 7, 8, 9])`.\n","\n","### Correcting the Previous Code:\n","\n","To correct the previous code snippet where `labels[:-1]` and `labels[-1]` were used, ensure that they are correctly applied within the context of your dataset and task. For example, if you're concatenating or processing batches of labels, use these syntaxes appropriately to access the desired subsets of the `labels` list.\n","\n","```python\n","# Example usage of labels[:-1] and labels[-1] in concatenation or processing\n","concatenated_labels = np.concatenate([np.concatenate(labels[:-1]), np.concatenate([labels[-1]])])\n","print(\"Concatenated Labels:\", concatenated_labels)\n","```"],"metadata":{"id":"Rk6KPoJ9m7DV"}},{"cell_type":"code","source":["cm = confusion_matrix(lab, pred)\n","print(cm)\n","plt.figure(figsize=(16,16))\n","\n","sns.heatmap(cm, annot=True,)\n","plt.title('Confusion matrix')\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')"],"metadata":{"id":"XajjlbQQZmbb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Testing"],"metadata":{"id":"G6kNxFcPjlMg"}},{"cell_type":"code","source":["inputs = tokenizer([\"Please how do i go about the account creation? \",\n","                    \"After setting up my account, i feel like i need to change it. How do i go about that?\",\n","                    \"how do i know how much i need to pay?\",\n","                    \"purchased a product, which i now want to change\"\n","                    ], padding=True,return_tensors=\"tf\")\n","\n","logits = model(**inputs).logits\n","outputs=tf.argmax(logits,axis=-1).numpy()"],"metadata":{"id":"VV9utCavZme5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(outputs)"],"metadata":{"id":"2YawrfPIZmiz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reverse_dict_intents={i:intents[i] for i in range(len(intents))}\n","print(reverse_dict_intents)"],"metadata":{"id":"mxVrr3GbZmmI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in outputs:\n","  print(reverse_dict_intents[i])"],"metadata":{"id":"5E4btAclZmp1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7stWFahMZmtY"},"execution_count":null,"outputs":[]}]}