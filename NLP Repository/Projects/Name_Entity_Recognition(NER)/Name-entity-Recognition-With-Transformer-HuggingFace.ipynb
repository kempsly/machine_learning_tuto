{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0Bp0io8oDNbdlJFyVZm4h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Installation"],"metadata":{"id":"gkio4WQeoGuf"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LyaTM-Afn2-h"},"outputs":[],"source":["!pip install transformers datasets evaluate\n","!pip install seqeval"]},{"cell_type":"markdown","source":["#IMport Statements"],"metadata":{"id":"71EHnzA_ovaw"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import sklearn_pandas\n","from sklearn.metrics import confusion_matrix, roc_curve\n","import seaborn as sns\n","import datetime\n","import pathlib\n","import io\n","import os\n","import re\n","import string\n","import evaluate\n","import time\n","from numpy import random\n","import gensim.downloader as api\n","from PIL import Image\n","import tensorflow_datasets as tfds\n","import tensorflow_probability as tfp\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras.layers import Dense,Flatten,InputLayer,BatchNormalization,Dropout,Input,LayerNormalization\n","from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n","from tensorflow.keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n","from tensorflow.keras.optimizers import Adam\n","from google.colab import drive\n","from google.colab import files\n","from datasets import load_dataset\n","from transformers import (BertTokenizerFast,TFBertTokenizer,BertTokenizer,RobertaTokenizerFast,DataCollatorForTokenClassification,\n","                          DataCollatorWithPadding,TFRobertaForSequenceClassification,TFBertForSequenceClassification,\n","                          TFBertModel,create_optimizer,TFRobertaForTokenClassification,TFAutoModelForTokenClassification,)"],"metadata":{"id":"5m5yGVSkoAFo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE=16\n","NUM_EPOCHS=2"],"metadata":{"id":"ztKBuFegoAIe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Preparation"],"metadata":{"id":"JEk811zIo77H"}},{"cell_type":"code","source":["dataset = load_dataset(\"conll2003\")"],"metadata":{"id":"0ySbIB3OoALb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset"],"metadata":{"id":"jDjRulN4oAOa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset['train'][20]"],"metadata":{"id":"lZkJo6qeoARh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_id=\"roberta-base\"\n","tokenizer=RobertaTokenizerFast.from_pretrained(model_id,add_prefix_space=True)"],"metadata":{"id":"BzR5eIeLoAUY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = tokenizer(dataset[\"train\"][20][\"tokens\"], is_split_into_words=True,)\n","inputs.tokens()"],"metadata":{"id":"sFix9ssJoAXP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(dataset['train'][20])"],"metadata":{"id":"KmRsm90voAZ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(inputs.word_ids())\n","print(dataset['train'][20]['ner_tags'])"],"metadata":{"id":"VnC5Q6xcoAcs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def align_labels_with_tokens(labels, word_ids):\n","    new_labels = []\n","    current_word = None\n","    for word_id in word_ids:\n","        if word_id != current_word:\n","            # Start of a new word!\n","            current_word = word_id\n","            label = -100 if word_id is None else labels[word_id]\n","            new_labels.append(label)\n","        elif word_id is None:\n","            # Special token\n","            new_labels.append(-100)\n","        else:\n","            # Same word as previous token\n","            label = labels[word_id]\n","            # If the label is B-XXX we change it to I-XXX\n","            if label % 2 == 1:\n","                label += 1\n","            new_labels.append(label)\n","\n","    return new_labels"],"metadata":{"id":"VZ1U5yOboAfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = dataset[\"train\"][20][\"ner_tags\"]\n","word_ids = inputs.word_ids()\n","print(labels)\n","print(align_labels_with_tokens(labels, word_ids))"],"metadata":{"id":"Ie0LH7oXoAia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenizer_function(dataset):\n","  out=tokenizer(dataset[\"tokens\"],truncation=True,is_split_into_words=True,)\n","  out['labels']=align_labels_with_tokens(dataset[\"ner_tags\"],out.word_ids())\n","  return out"],"metadata":{"id":"ljlLObNqoAla"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset=dataset.map(tokenizer_function,remove_columns=['id','tokens','pos_tags','chunk_tags','ner_tags',])"],"metadata":{"id":"0pFG3xgPoAod"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset"],"metadata":{"id":"F6A60uXVoArc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset['train'][20]"],"metadata":{"id":"xgVGuJQ-oAuY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_collator = DataCollatorForTokenClassification(\n","    tokenizer=tokenizer, return_tensors=\"tf\"\n",")"],"metadata":{"id":"EU5c7V9noAxn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf_train_dataset = tokenized_dataset[\"train\"].to_tf_dataset(\n","    collate_fn=data_collator,\n","    shuffle=True,\n","    batch_size=BATCH_SIZE,\n",")"],"metadata":{"id":"v7uXCguEoA0s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf_val_dataset = tokenized_dataset[\"validation\"].to_tf_dataset(\n","    collate_fn=data_collator,\n","    shuffle=False,\n","    batch_size=BATCH_SIZE,\n",")"],"metadata":{"id":"sE7-VMr0oA36"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in tf_train_dataset.take(1):\n","  print(i)"],"metadata":{"id":"-9kh-9iFoA6t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Modeling"],"metadata":{"id":"J0QYY5P2wooS"}},{"cell_type":"markdown","source":["##With TFRobertaForSequenceClassification"],"metadata":{"id":"H3icJbNhwvp4"}},{"cell_type":"code","source":["model=TFRobertaForTokenClassification.from_pretrained(\n","    model_id,\n","    num_labels=9,\n",")"],"metadata":{"id":"Nvf3-xo0oA9s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"HACLvRxroBA0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Training"],"metadata":{"id":"u9t12D-8xcyr"}},{"cell_type":"code","source":["batches_per_epoch = len(tokenized_dataset[\"train\"]) // BATCH_SIZE\n","total_train_steps = int(batches_per_epoch*NUM_EPOCHS)"],"metadata":{"id":"uHd48XLwoBD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer, schedule = create_optimizer(init_lr=2e-5,num_warmup_steps=0, num_train_steps=total_train_steps,)"],"metadata":{"id":"taD04XJdoBHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer=optimizer,)\n","    #metrics=[\"accuracy\"])"],"metadata":{"id":"mG8TO0DjoBKO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history=model.fit(\n","    tf_train_dataset,\n","    validation_data=tf_val_dataset,\n","    epochs=NUM_EPOCHS,)"],"metadata":{"id":"sCeBvWgdoBNU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model_loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"metadata":{"id":"8xsNGpfJoBQ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Evaluation"],"metadata":{"id":"y62z_YFWxuzS"}},{"cell_type":"code","source":["metric=evaluate.load(\"seqeval\")"],"metadata":{"id":"ry9lnLGzoBUE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ind_to_label={0:'O', 1:'B-PER',2:'I-PER',3:'B-ORG',4:'I-ORG',5:'B-LOC',6:'I-LOC',7:'B-MISC',8:'I-MISC'}\n","all_predictions = []\n","all_labels = []"],"metadata":{"id":"kqFk1unAoBXG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batch in tf_val_dataset:\n","  logits = model.predict(batch)[\"logits\"]\n","  labels = batch[\"labels\"].numpy()\n","  predictions = tf.argmax(logits, axis=-1).numpy()\n","  #print(labels)\n","  #print(predictions)\n","  for prediction, label in zip(predictions, labels):\n","    for predicted_idx, label_idx in zip(prediction, label):\n","      if label_idx == -100:\n","          continue\n","      all_predictions.append(ind_to_label[predicted_idx])\n","      all_labels.append(ind_to_label[label_idx])"],"metadata":{"id":"Qi_R-eI-oBaF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(all_predictions)\n","print(all_labels)"],"metadata":{"id":"ECEZhuwdoBdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metric.compute(predictions=[all_predictions], references=[all_labels])"],"metadata":{"id":"FQwdD8TaoBgJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Testing"],"metadata":{"id":"KmEqOZdjyKsc"}},{"cell_type":"code","source":["inputs=tokenizer([\"Wake Up JoeMarshal, you just got a call from UNESCO for a trip to India\"], padding=True,return_tensors=\"tf\")"],"metadata":{"id":"XZas0xGAoBjB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(inputs.tokens())\n","print(inputs.word_ids())\n","print(inputs['input_ids'])"],"metadata":{"id":"g4wi9yJ_oBmD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits = model(**inputs).logits\n","print(logits.shape)\n","print(tf.argmax(logits,axis=-1))"],"metadata":{"id":"vs3-sa4noBo-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ind_to_label={0:'O', 1:'B-PER',2:'I-PER',3:'B-ORG',4:'I-ORG',5:'B-LOC',6:'I-LOC',7:'B-MISC',8:'I-MISC'}\n","out_str=\"\"\n","current_index=0"],"metadata":{"id":"WSOCaTKOoBr4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(1,len(inputs.tokens())-1):\n","  if tf.argmax(logits,axis=-1)[0][i]!=0:\n","    out_str+=\" \"+str(inputs.tokens()[i])+\"--->\"+str(ind_to_label[tf.argmax(logits,axis=-1).numpy()[0][i]])\n","  else:\n","    out_str+=\" \"+str(inputs.tokens()[i])"],"metadata":{"id":"gxxGojweoBu9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(out_str.replace(\"Ġ\",\"\"))"],"metadata":{"id":"oahiHJkmoBx1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wdLRC6FgoB0j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4IDylhgHoB3h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wwBEj1pwoB6g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hUkTWfL3oB92"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Fp0Ci71GoCBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CEPaCZPFoCEn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"FT0_WxZWoCH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Tku1pflFoCK3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3bXw3fKPoCN8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wskdZjWRoCRA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RAYcG88RoCT4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1wVJ0K_joCXX"},"execution_count":null,"outputs":[]}]}